<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Serialization | Tilting at Rabbit Holes]]></title>
  <link href="http://erickt.github.io/blog/categories/serialization/atom.xml" rel="self"/>
  <link href="http://erickt.github.io/"/>
  <updated>2014-12-13T18:28:16-08:00</updated>
  <id>http://erickt.github.io/</id>
  <author>
    <name><![CDATA[Erick Tryzelaar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 3: Introducing Serde]]></title>
    <link href="http://erickt.github.io/blog/2014/12/13/rewriting-rust-serialization/"/>
    <updated>2014-12-13T14:40:18-08:00</updated>
    <id>http://erickt.github.io/blog/2014/12/13/rewriting-rust-serialization</id>
    <content type="html"><![CDATA[<p>There&rsquo;s been a long digression over the past month
(<a href="http://erickt.github.io/blog/2014/11/19/adventures-in-debugging-a-potential-osx-kernel-bug/">possible kernel bugs</a>,
<a href="http://erickt.github.io/blog/2014/11/22/benchmarking-is-confusing/">benchmarking Writers</a>,
and
<a href="https://github.com/rust-lang/rust/pull/19574">don&rsquo;t believe in magic, folks</a>), but I&rsquo;m back
into serialization. Woo! Here&rsquo;s
<a href="http://erickt.github.io/blog/2014/10/28/serialization/">part 1</a> and
<a href="http://erickt.github.io/blog/2014/11/03/performance/">part 2</a>), Rust&rsquo;s
<a href="http://erickt.github.io/blog/2014/11/03/performance/">part 2.1</a>), Rust&rsquo;s
<a href="http://erickt.github.io/blog/2014/11/03/performance/">part 2.2</a>) if you need
to catch up.</p>

<p>So <code>libserialize</code> has some pretty serious downsides. It&rsquo;s slow, it&rsquo;s got this
weird recursive closure thing going on, and it can&rsquo;t even represent enum types
like a <code>serialize::json::Json</code>. We need a new solution, and while I was at it,
we ended up with two: <a href="https://github.com/erickt/rust-serde">serde</a> and
<a href="https://github.com/erickt/rust-serde/tree/master/serde2">serde2</a>. Both are
different approaches to trying to address these problems. The biggest one being
the type representation problem.</p>

<h2>Serde Version 1</h2>

<h3>Deserialization</h3>

<p>I want to start with deserialization first, as that&rsquo;s really the interesting
bit. To repeat myself a little bit from
<a href="https://erickt.github.io/blog/2014/10/28/serialization/">part 1</a>,
here is a generic json <code>Value</code> enum:</p>

<pre><code class="rust">pub enum Value {
    I64(i64),
    U64(u64),
    F64(f64),
    String(String),
    Boolean(bool),
    Array(Vec&lt;Value&gt;),
    Object(TreeMap&lt;String, Value&gt;),
    Null,
}
</code></pre>

<p>To deserialize a string like <code>[1, true]</code> into
<code>Array(vec![I64(1), Boolean(true)])</code>, we need to peek at one character ahead
(ignoring whitespace) in order to discover what is the type of the next value.
We then can use that knowledge to pick the right variant, and parse the next
value correctly. While I haven&rsquo;t formally studied this stuff, I believe this
can be more formally stated as <code>Value</code> requires at least a LL(1) grammar,
but since <code>libserialize</code> supports no lookahead, so at most it can handle LL(0)
grammars.</p>

<p>Since I was thinking of this problem in terms of grammars, I wanted to take a
page out of their book and implement generic deserialization in this style.
<code>serde::de::Deserializer</code>s are then an <code>Iterator&lt;serde::de::Token&gt;</code> lexer that
produces a token stream, and <code>serde::de::Deserialize</code>s are a parser that
consumes this stream to produce a value. Here&rsquo;s <code>serde::de::Token</code>, which can
represent nearly all the rust types:</p>

<pre><code class="rust">pub enum Token {
    Null,
    Bool(bool),
    Int(int),
    I8(i8),
    I16(i16),
    I32(i32),
    I64(i64),
    Uint(uint),
    U8(u8),
    U16(u16),
    U32(u32),
    U64(u64),
    F32(f32),
    F64(f64),
    Char(char),
    Str(&amp;'static str),
    String(String),

    Option(bool),     // true if the option has a value

    TupleStart(uint), // estimate of the number of values

    StructStart(
        &amp;'static str, // the struct name
        uint,         // estimate of the number of (string, value) pairs
    ),

    EnumStart(
        &amp;'static str, // the enum name
        &amp;'static str, // the variant name
        uint          // estimate of the number of values
    ),

    SeqStart(uint), // number of values

    MapStart(uint), // number of (value, value) pairs

    End,
}
</code></pre>

<p>The <code>serde::de::Deserialize</code> stream must generate tokens that follow this
grammar:</p>

<pre><code class="antlr">value ::= Null
        | Bool
        | Int
        | ...
        | option
        | tuple
        | struct
        | enum
        | sequence
        | map
        ;

option ::= Option value
         | Option
         ;

tuple := TupleStart value* End;

struct := StructStart (Str value)* End;

enum := EnumStart value* End;

sequence := SeqStart value* End;

map := MapStart (value value)* End;
</code></pre>

<p>For performance reasons, there is no separator in the compound grammar.</p>

<p>Finishing up this section are the actual traits, <code>Deserialize</code> and <code>Deserializer</code>:</p>

<pre><code class="rust">pub trait Deserialize&lt;D: Deserializer&lt;E&gt;, E&gt; {
    fn deserialize(d: &amp;mut D) -&gt; Result&lt;Self, E&gt; {
        let token = try!(d.expect_token());
        Deserialize::deserialize_token(d, token)
    }

    fn deserialize_token(d: &amp;mut D, token: Token) -&gt; Result&lt;Self, E&gt;;
}

pub trait Deserializer&lt;E&gt;: Iterator&lt;Result&lt;Token, E&gt;&gt; {
    /// Called when a `Deserialize` expected more tokens, but the
    /// `Deserializer` was empty.
    fn end_of_stream_error(&amp;mut self) -&gt; E;

    /// Called when a `Deserializer` was unable to properly parse the stream.
    fn syntax_error(&amp;mut self, token: Token, expected: &amp;'static [TokenKind]) -&gt; E;

    /// Called when a named structure or enum got a name that it didn't expect.
    fn unexpected_name_error(&amp;mut self, token: Token) -&gt; E;

    /// Called when a value was unable to be coerced into another value.
    fn conversion_error(&amp;mut self, token: Token) -&gt; E;

    /// Called when a `Deserialize` structure did not deserialize a field
    /// named `field`.
    fn missing_field&lt;
        T: Deserialize&lt;Self, E&gt;
    &gt;(&amp;mut self, field: &amp;'static str) -&gt; Result&lt;T, E&gt;;

    /// Called when a `Deserialize` has decided to not consume this token.
    fn ignore_field(&amp;mut self, _token: Token) -&gt; Result&lt;(), E&gt; {
        let _: IgnoreTokens = try!(Deserialize::deserialize(self));
        Ok(())
    }

    #[inline]
    fn expect_token(&amp;mut self) -&gt; Result&lt;Token, E&gt; {
        match self.next() {
            Some(Ok(token)) =&gt; Ok(token),
            Some(Err(err)) =&gt; Err(err),
            None =&gt; Err(self.end_of_stream_error()),
        }
    }

    ...
}
</code></pre>

<p>The <code>Deserialize</code> trait is kept pretty slim, and is how lookahead is
implemented. <code>Deserializer</code> is an enhanced <code>Iterator&lt;Result&lt;Token, E&gt;&gt;</code>, with
many helpful default methods. Here are them in action. First we&rsquo;ll start with
what&rsquo;s probably the simplest <code>Deserializer</code>, which just wraps a <code>Vec&lt;Token&gt;</code>:</p>

<pre><code class="rust">enum Error {
    EndOfStream,
    SyntaxError(Vec&lt;TokenKind&gt;),
    UnexpectedName,
    ConversionError,
    MissingField(&amp;'static str),
}

struct TokenDeserializer&lt;Iter&gt; {
    tokens: Iter,
}

impl&lt;Iter: Iterator&lt;Token&gt;&gt; TokenDeserializer&lt;Iter&gt; {
    fn new(tokens: Iter) -&gt; TokenDeserializer&lt;Iter&gt; {
        TokenDeserializer {
            tokens: tokens,
        }
    }
}

impl&lt;Iter: Iterator&lt;Token&gt;&gt; Iterator&lt;Result&lt;Token, Error&gt;&gt; for TokenDeserializer&lt;Iter&gt; {
    fn next(&amp;mut self) -&gt; option::Option&lt;Result&lt;Token, Error&gt;&gt; {
        match self.tokens.next() {
            None =&gt; None,
            Some(token) =&gt; Some(Ok(token)),
        }
    }
}

impl&lt;Iter: Iterator&lt;Token&gt;&gt; Deserializer&lt;Error&gt; for TokenDeserializer&lt;Iter&gt; {
    fn end_of_stream_error(&amp;mut self) -&gt; Error {
        Error::EndOfStream
    }

    fn syntax_error(&amp;mut self, _token: Token, expected: &amp;[TokenKind]) -&gt; Error {
        Error::SyntaxError(expected.to_vec())
    }

    fn unexpected_name_error(&amp;mut self, _token: Token) -&gt; Error {
        Error::UnexpectedName
    }

    fn conversion_error(&amp;mut self, _token: Token) -&gt; Error {
        Error::ConversionError
    }

    #[inline]
    fn missing_field&lt;
        T: Deserialize&lt;TokenDeserializer&lt;Iter&gt;, Error&gt;
    &gt;(&amp;mut self, field: &amp;'static str) -&gt; Result&lt;T, Error&gt; {
        Err(Error::MissingField(field))
    }
}
</code></pre>

<p>Overall it should be pretty straight forward. As usual, error handling makes
things a bit noisier, but hopefully it&rsquo;s not too onerous. Next is a
<code>Deserialize</code> for <code>bool</code>:</p>

<pre><code class="rust">impl&lt;D: Deserializer&lt;E&gt;, E&gt; Deserialize&lt;D, E&gt; for bool {
    #[inline]
    fn deserialize_token(d: &amp;mut D, token: Token) -&gt; Result&lt;bool, E&gt; {
        d.expect_bool(token)
    }
}

pub trait Deserializer&lt;E&gt;: Iterator&lt;Result&lt;Token, E&gt;&gt; {
    ...

    #[inline]
    fn expect_bool(&amp;mut self, token: Token) -&gt; Result&lt;bool, E&gt; {
        match token {
            Token::Bool(value) =&gt; Ok(value),
            token =&gt; {
                static EXPECTED_TOKENS: &amp;'static [TokenKind] = &amp;[
                    TokenKind::BoolKind,
                ];
                Err(self.syntax_error(token, EXPECTED_TOKENS))
            }
        }
    }


    ...
}
</code></pre>

<p>Simple! Sequences are a bit more tricky. Here&rsquo;s <code>Deserialize</code> a <code>Vec&lt;T&gt;</code>. We
use a helper adaptor <code>SeqDeserializer</code> to deserialize from all types that
implement <code>FromIterator</code>:</p>

<pre><code class="rust">impl&lt;
    D: Deserializer&lt;E&gt;,
    E,
    T: Deserialize&lt;D ,E&gt;
&gt; Deserialize&lt;D, E&gt; for Vec&lt;T&gt; {
    #[inline]
    fn deserialize_token(d: &amp;mut D, token: Token) -&gt; Result&lt;Vec&lt;T&gt;, E&gt; {
        d.expect_seq(token)
    }
}

pub trait Deserializer&lt;E&gt;: Iterator&lt;Result&lt;Token, E&gt;&gt; {
    ...

    #[inline]
    fn expect_seq&lt;
        T: Deserialize&lt;Self, E&gt;,
        C: FromIterator&lt;T&gt;
    &gt;(&amp;mut self, token: Token) -&gt; Result&lt;C, E&gt; {
        let len = try!(self.expect_seq_start(token));
        let mut err = None;

        let collection: C = {
            let d = SeqDeserializer {
                d: self,
                len: len,
                err: &amp;mut err,
            };

            d.collect()
        };

        match err {
            Some(err) =&gt; Err(err),
            None =&gt; Ok(collection),
        }
    }

    ...
}

struct SeqDeserializer&lt;'a, D: 'a, E: 'a&gt; {
    d: &amp;'a mut D,
    len: uint,
    err: &amp;'a mut Option&lt;E&gt;,
}

impl&lt;
    'a,
    D: Deserializer&lt;E&gt;,
    E,
    T: Deserialize&lt;D, E&gt;
&gt; Iterator&lt;T&gt; for SeqDeserializer&lt;'a, D, E&gt; {
    #[inline]
    fn next(&amp;mut self) -&gt; option::Option&lt;T&gt; {
        match self.d.expect_seq_elt_or_end() {
            Ok(next) =&gt; {
                self.len -= 1;
                next
            }
            Err(err) =&gt; {
                *self.err = Some(err);
                None
            }
        }
    }

    #[inline]
    fn size_hint(&amp;self) -&gt; (uint, option::Option&lt;uint&gt;) {
        (self.len, Some(self.len))
    }
}
</code></pre>

<p>Last is a struct deserializer. This relies on a simple state machine in order
to deserialize from out of order maps:</p>

<pre><code class="rust">struct Foo {
    a: (),
    b: uint,
    c: TreeMap&lt;String, Option&lt;char&gt;&gt;,
}

impl&lt;
    D: Deserializer&lt;E&gt;,
    E
&gt; Deserialize&lt;D, E&gt; for Foo {
    #[inline]
    fn deserialize_token(d: &amp;mut D, token: Token) -&gt; Result&lt;Foo, E&gt; {
        try!(d.expect_struct_start(token, "Foo"));

        let mut a = None;
        let mut b = None;
        let mut c = None;

        static FIELDS: &amp;'static [&amp;'static str] = &amp;["a", "b", "c"];

        loop {
            let idx = match try!(d.expect_struct_field_or_end(FIELDS)) {
                Some(idx) =&gt; idx,
                None =&gt; { break; }
            };

            match idx {
                Some(0) =&gt; { a = Some(try!(d.expect_struct_value())); }
                Some(1) =&gt; { b = Some(try!(d.expect_struct_value())); }
                Some(2) =&gt; { c = Some(try!(d.expect_struct_value())); }
                Some(_) =&gt; unreachable!(),
                None =&gt; { let _: IgnoreTokens = try!(Deserialize::deserialize(d)); }
            }
        }

        Ok(Foo { a: a.unwrap(), b: b.unwrap(), c: c.unwrap() })
    }
}
</code></pre>

<p>It&rsquo;s more complicated than <code>libserialize</code>&rsquo;s struct parsing, but it performs
much better because it can handle out of order maps without buffering tokens.</p>

<h3>Serialization</h3>

<p>Serialization&rsquo;s story is a much simpler one. Conceptually
<code>serde::ser::Serializer</code>/<code>serde::ser::Serialize</code> are inspired by the
deserialization story, but we don&rsquo;t need the tagged tokens because we already
know the types. Here are the traits:</p>

<pre><code class="rust">pub trait Serialize&lt;S: Serializer&lt;E&gt;, E&gt; {
    fn serialize(&amp;self, s: &amp;mut S) -&gt; Result&lt;(), E&gt;;
}

pub trait Serializer&lt;E&gt; {
    fn serialize_null(&amp;mut self) -&gt; Result&lt;(), E&gt;;

    fn serialize_bool(&amp;mut self, v: bool) -&gt; Result&lt;(), E&gt;;

    #[inline]
    fn serialize_int(&amp;mut self, v: int) -&gt; Result&lt;(), E&gt; {
        self.serialize_i64(v as i64)
    }

    #[inline]
    fn serialize_i8(&amp;mut self, v: i8) -&gt; Result&lt;(), E&gt; {
        self.serialize_i64(v as i64)
    }

    #[inline]
    fn serialize_i16(&amp;mut self, v: i16) -&gt; Result&lt;(), E&gt; {
        self.serialize_i64(v as i64)
    }

    #[inline]
    fn serialize_i32(&amp;mut self, v: i32) -&gt; Result&lt;(), E&gt; {
        self.serialize_i64(v as i64)
    }

    #[inline]
    fn serialize_i64(&amp;mut self, v: i64) -&gt; Result&lt;(), E&gt;;

    #[inline]
    fn serialize_uint(&amp;mut self, v: uint) -&gt; Result&lt;(), E&gt; {
        self.serialize_u64(v as u64)
    }

    #[inline]
    fn serialize_u8(&amp;mut self, v: u8) -&gt; Result&lt;(), E&gt; {
        self.serialize_u64(v as u64)
    }

    #[inline]
    fn serialize_u16(&amp;mut self, v: u16) -&gt; Result&lt;(), E&gt; {
        self.serialize_u64(v as u64)
    }

    #[inline]
    fn serialize_u32(&amp;mut self, v: u32) -&gt; Result&lt;(), E&gt; {
        self.serialize_u64(v as u64)
    }

    #[inline]
    fn serialize_u64(&amp;mut self, v: u64) -&gt; Result&lt;(), E&gt;;

    #[inline]
    fn serialize_f32(&amp;mut self, v: f32) -&gt; Result&lt;(), E&gt; {
        self.serialize_f64(v as f64)
    }

    fn serialize_f64(&amp;mut self, v: f64) -&gt; Result&lt;(), E&gt;;

    fn serialize_char(&amp;mut self, v: char) -&gt; Result&lt;(), E&gt;;

    fn serialize_str(&amp;mut self, v: &amp;str) -&gt; Result&lt;(), E&gt;;

    fn serialize_tuple_start(&amp;mut self, len: uint) -&gt; Result&lt;(), E&gt;;
    fn serialize_tuple_elt&lt;
        T: Serialize&lt;Self, E&gt;
    &gt;(&amp;mut self, v: &amp;T) -&gt; Result&lt;(), E&gt;;
    fn serialize_tuple_end(&amp;mut self) -&gt; Result&lt;(), E&gt;;

    fn serialize_struct_start(&amp;mut self, name: &amp;str, len: uint) -&gt; Result&lt;(), E&gt;;
    fn serialize_struct_elt&lt;
        T: Serialize&lt;Self, E&gt;
    &gt;(&amp;mut self, name: &amp;str, v: &amp;T) -&gt; Result&lt;(), E&gt;;
    fn serialize_struct_end(&amp;mut self) -&gt; Result&lt;(), E&gt;;

    fn serialize_enum_start(&amp;mut self, name: &amp;str, variant: &amp;str, len: uint) -&gt; Result&lt;(), E&gt;;
    fn serialize_enum_elt&lt;
        T: Serialize&lt;Self, E&gt;
    &gt;(&amp;mut self, v: &amp;T) -&gt; Result&lt;(), E&gt;;
    fn serialize_enum_end(&amp;mut self) -&gt; Result&lt;(), E&gt;;

    fn serialize_option&lt;
        T: Serialize&lt;Self, E&gt;
    &gt;(&amp;mut self, v: &amp;Option&lt;T&gt;) -&gt; Result&lt;(), E&gt;;

    fn serialize_seq&lt;
        T: Serialize&lt;Self, E&gt;,
        Iter: Iterator&lt;T&gt;
    &gt;(&amp;mut self, iter: Iter) -&gt; Result&lt;(), E&gt;;

    fn serialize_map&lt;
        K: Serialize&lt;Self, E&gt;,
        V: Serialize&lt;Self, E&gt;,
        Iter: Iterator&lt;(K, V)&gt;
    &gt;(&amp;mut self, iter: Iter) -&gt; Result&lt;(), E&gt;;
}
</code></pre>

<p>There are many default methods, so only a handful of implementations need to be
specified. Now lets look at how they are used. Here&rsquo;s a simple
<code>AssertSerializer</code> that I use in my test suite to make sure I&rsquo;m serializing
properly:</p>

<pre><code class="rust">struct AssertSerializer&lt;Iter&gt; {
    iter: Iter,
}

impl&lt;'a, Iter: Iterator&lt;Token&lt;'a&gt;&gt;&gt; AssertSerializer&lt;Iter&gt; {
    fn new(iter: Iter) -&gt; AssertSerializer&lt;Iter&gt; {
        AssertSerializer {
            iter: iter,
        }
    }

    fn serialize&lt;'b&gt;(&amp;mut self, token: Token&lt;'b&gt;) -&gt; Result&lt;(), Error&gt; {
        let t = match self.iter.next() {
            Some(t) =&gt; t,
            None =&gt; { panic!(); }
        };

        assert_eq!(t, token);

        Ok(())
    }
}

impl&lt;'a, Iter: Iterator&lt;Token&lt;'a&gt;&gt;&gt; Serializer&lt;Error&gt; for AssertSerializer&lt;Iter&gt; {
    fn serialize_null(&amp;mut self) -&gt; Result&lt;(), Error&gt; {
        self.serialize(Token::Null)
    }
    fn serialize_bool(&amp;mut self, v: bool) -&gt; Result&lt;(), Error&gt; {
        self.serialize(Token::Bool(v))
    }
    fn serialize_int(&amp;mut self, v: int) -&gt; Result&lt;(), Error&gt; {
        self.serialize(Token::Int(v))
    }
    ...
}
</code></pre>

<p>Implementing <code>Serialize</code> for values follows the same pattern. Here&rsquo;s <code>bool</code>:</p>

<pre><code>impl&lt;S: Serializer&lt;E&gt;, E&gt; Serialize&lt;S, E&gt; for bool {
    #[inline]
    fn serialize(&amp;self, s: &amp;mut S) -&gt; Result&lt;(), E&gt; {
        s.serialize_bool(*self)
    }
}
</code></pre>

<p><code>Vec&lt;T&gt;</code>:</p>

<pre><code class="rust">impl&lt;
    S: Serializer&lt;E&gt;,
    E,
    T: Serialize&lt;S, E&gt;
&gt; Serialize&lt;S, E&gt; for Vec&lt;T&gt; {
    #[inline]
    fn serialize(&amp;self, s: &amp;mut S) -&gt; Result&lt;(), E&gt; {
        s.serialize_seq(self.iter())
    }
}

pub trait Serializer&lt;E&gt; {
    ...

    fn serialize_seq&lt;
        T: Serialize&lt;AssertSerializer&lt;Iter&gt;, Error&gt;,
        SeqIter: Iterator&lt;T&gt;
    &gt;(&amp;mut self, mut iter: SeqIter) -&gt; Result&lt;(), Error&gt; {
        let (len, _) = iter.size_hint();
        try!(self.serialize(Token::SeqStart(len)));
        for elt in iter {
            try!(elt.serialize(self));
        }
        self.serialize(Token::SeqEnd)
    }

    ...
}
</code></pre>

<p>And structs:</p>

<pre><code class="rust">struct Foo {
    a: (),
    b: uint,
    c: TreeMap&lt;String, Option&lt;char&gt;&gt;,
}

impl&lt;
  S: Serializer&lt;E&gt;,
  E
&gt; Serialize&lt;S, E&gt; for Foo {
    fn serialize(&amp;self, s: &amp;mut S) -&gt; Result&lt;(), E&gt; {
        try!(s.serialize_struct_start("Foo", 2u));
        try!(s.serialize_struct_elt("a", &amp;self.a));
        try!(s.serialize_struct_elt("b", &amp;self.b));
        try!(s.serialize_struct_elt("c", &amp;self.c));
        s.serialize_struct_end()
    }
}
</code></pre>

<p>Much simpler than deserialization.</p>

<h2>Performance</h2>

<p>So how does it perform? Here&rsquo;s the serialization benchmarks, with yet another
ordering. This time sorted by the performance:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library         </th>
<th> format                 </th>
<th> serialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> capnproto-rust  </td>
<td> Cap&#8217;n Proto (unpacked) </td>
<td> 4349                 </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto    </td>
<td> Cap&#8217;n Proto            </td>
<td> 3824.20              </td>
</tr>
<tr>
<td> Rust     </td>
<td> bincode         </td>
<td> Binary                 </td>
<td> 1020                 </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf    </td>
<td> Protocol Buffers       </td>
<td> 596.78               </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust  </td>
<td> Cap&#8217;n Proto (packed)   </td>
<td> 583                  </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-msgpack    </td>
<td> MessagePack            </td>
<td> 397                  </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-protobuf   </td>
<td> Protocol Buffers       </td>
<td> 357                  </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson       </td>
<td> JSON                   </td>
<td> 304                  </td>
</tr>
<tr>
<td> <strong>Rust</strong> </td>
<td> <strong>serde::json</strong> </td>
<td> <strong>JSON</strong>               </td>
<td> <strong>222</strong>              </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf      </td>
<td> Protocol Buffers       </td>
<td> 214.68               </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson          </td>
<td> JSON                   </td>
<td> 147.37               </td>
</tr>
<tr>
<td> Rust     </td>
<td> serialize::json </td>
<td> JSON                   </td>
<td> 147                  </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json   </td>
<td> JSON                   </td>
<td> 80.49                </td>
</tr>
</tbody>
</table>


<p><code>serde::json</code> is doing pretty good! It still has got a ways to go to catch up
to <a href="https://github.com/miloyip/rapidjson">rapidjson</a>, but it&rsquo;s pretty cool it&rsquo;s
beating <a href="https://github.com/golang/protobuf">goprotobuf</a> out of the box :)</p>

<p>Here are the deserialization numbers:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library         </th>
<th> format                  </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> capnproto-rust  </td>
<td> Cap&#8217;n Proto (unpacked)  </td>
<td> 2185                   </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto    </td>
<td> Cap&#8217;n Proto (zero copy) </td>
<td> 1407.95                </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto    </td>
<td> Cap&#8217;n Proto             </td>
<td> 711.77                 </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust  </td>
<td> Cap&#8217;n Proto (packed)    </td>
<td> 351                    </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf    </td>
<td> Protocol Buffers        </td>
<td> 272.68                 </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson       </td>
<td> JSON (sax)              </td>
<td> 189                    </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson       </td>
<td> JSON (dom)              </td>
<td> 162                    </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-msgpack    </td>
<td> MessagePack             </td>
<td> 138                    </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-protobuf   </td>
<td> Protocol Buffers        </td>
<td> 129                    </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson          </td>
<td> JSON                    </td>
<td> 95.06                  </td>
</tr>
<tr>
<td> Rust     </td>
<td> bincode         </td>
<td> Binary                  </td>
<td> 80                     </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf      </td>
<td> Protocol Buffers        </td>
<td> 79.78                  </td>
</tr>
<tr>
<td> <strong>Rust</strong> </td>
<td> <strong>serde::json</strong> </td>
<td> <strong>JSON</strong>                </td>
<td> <strong>67</strong>                 </td>
</tr>
<tr>
<td> Rust     </td>
<td> serialize::json </td>
<td> JSON                    </td>
<td> 24                     </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json   </td>
<td> JSON                    </td>
<td> 22.79                  </td>
</tr>
</tbody>
</table>


<p>Well on the plus side, <code>serde::json</code> nearly 3 times faster than
<code>libserialize::json</code>. On the downside rapidjson is nearly 3 times faster than
us in it&rsquo;s SAX style parsing. Even the newly added deserialization support in
<a href="https://github.com/pquerna/ffjson">ffjson</a> is 1.4 times faster than us. So we
got more work cut out for us!</p>

<p>Next time, serde2!</p>

<p>PS: I&rsquo;m definitely getting close to the end of my story, and while I have some
better numbers with serde2, nothing is quite putting me in the rapidjson
range. Anyone want to help optimize
<a href="https://github.com/erickt/rust-serde">serde</a>? I would greatly appreciate the help!</p>

<p>PPS: I&rsquo;ve gotten a number of requests for my
<a href="https://github.com/erickt/rust-serialization-benchmarks">serialization benchmarks</a>
to be ported over to other languages and libraries. Especially a C++ version
of Cap&#8217;n Proto. Unfortunately I don&rsquo;t really have the time to do it myself.
Would anyone be up for helping to implement it?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 2.2: More Benchmarks]]></title>
    <link href="http://erickt.github.io/blog/2014/11/13/benchmarks-2/"/>
    <updated>2014-11-13T09:07:36-08:00</updated>
    <id>http://erickt.github.io/blog/2014/11/13/benchmarks-2</id>
    <content type="html"><![CDATA[<p>Back to the benchmarks! I got some great comments on
<a href="https://www.reddit.com/r/rust/comments/2lzc9n/rust_serialization_part_21_now_with_more/">reddit</a>,
So I wanted to do another post to update my numbers. Here&rsquo;s what I changed:</p>

<ul>
<li>I wasn&rsquo;t consistent on whether or not the serialization benchmarks included
Some tests are including the allocation of a buffer to write into. I&rsquo;ve
  changed it so most are reusing one, which speeds everything up (especially
capnproto-rust!). This does depend on
<a href="https://github.com/rust-lang/rust/pull/18885">#18885</a> landing though.</li>
<li>I&rsquo;ve added <a href="https://github.com/TyOverby/bincode">bincode</a>, which serializes
values as raw bytes. Quite speedy too! Not nearly as fast as Cap&#8217;n Proto though.</li>
<li>I&rsquo;ve changed <code>C++</code> and <code>Rust</code> JSON tests to serialize enums as uints.</li>
<li>I added the time it takes to create the populate the structures. I&rsquo;m betting
  the reason the Rust numbers are so high is that we&rsquo;re allocating strings. Not
sure if the other languages are able to avoid that allocation.</li>
</ul>


<hr />

<p>JSON:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library         </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> serialize::json </td>
<td> 1127            </td>
<td> 117                  </td>
<td> 26                     </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson (dom) </td>
<td> 546             </td>
<td> 281                  </td>
<td> 144                    </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson (dom) </td>
<td> 546             </td>
<td> 281                  </td>
<td> 181                    </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json   </td>
<td> 343             </td>
<td> 63.99                </td>
<td> 22.46                  </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson          </td>
<td> 343             </td>
<td> 144.60               </td>
<td> (not supported)        </td>
</tr>
</tbody>
</table>


<hr />

<p>Cap&#8217;n Proto:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library                   </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> capnproto-rust (unpacked) </td>
<td> 325             </td>
<td> 4977                 </td>
<td> 2251                   </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust (packed)   </td>
<td> 325             </td>
<td> 398                  </td>
<td> 246                    </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto              </td>
<td> 2368            </td>
<td> 2226.71              </td>
<td> 450                    </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto (zero copy)  </td>
<td> 2368            </td>
<td> 2226.71              </td>
<td> 1393.3                 </td>
</tr>
</tbody>
</table>


<hr />

<p>Protocol Buffers:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library       </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> rust-protobuf </td>
<td> 1041            </td>
<td> 370                  </td>
<td> 118                    </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf    </td>
<td> 1133            </td>
<td> 138.27               </td>
<td> 91.18                  </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf  </td>
<td> 343             </td>
<td> 472.69               </td>
<td> 295.33                 </td>
</tr>
</tbody>
</table>


<hr />

<p>Misc:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library      </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> rust-msgpack </td>
<td> 1143            </td>
<td> 454                  </td>
<td> 144                    </td>
</tr>
<tr>
<td> Rust     </td>
<td> bincode      </td>
<td> 1143            </td>
<td> 1149                 </td>
<td> 82                     </td>
</tr>
</tbody>
</table>


<p>Anyone want to add more C/Go/Rust/Java/etc benchmarks?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 2.1: Benchmarks]]></title>
    <link href="http://erickt.github.io/blog/2014/11/11/benchmarks/"/>
    <updated>2014-11-11T08:11:34-08:00</updated>
    <id>http://erickt.github.io/blog/2014/11/11/benchmarks</id>
    <content type="html"><![CDATA[<p>After <a href="http://erickt.github.io/blog/2014/11/03/performance/">part 2</a> I received
a couple requests to add in a couple other rust serialization libraries. So one
thing led to another, and now I&rsquo;ve got a benchmark suite I&rsquo;m calling
<a href="https://github.com/erickt/rust-serialization-benchmarks">rust-serialization-benchmarks</a>.
Really creative name, eh? This includes all the other benchmarks I referred to
previously, as well as <a href="https://github.com/dwrensha/capnproto-rust">capnproto</a>,
<a href="https://github.com/mneumann/rust-msgpack">msgpack</a>, and
<a href="https://github.com/stepancheg/rust-protobuf">protobuf</a>.</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library             </th>
<th> format                  </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s)   </th>
</tr>
</thead>
<tbody>
<tr>
<td> C++      </td>
<td> rapidjson           </td>
<td> JSON (dom)              </td>
<td> 233                  </td>
<td> 102                      </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson           </td>
<td> JSON (sax)              </td>
<td> 233                  </td>
<td> 124                      </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json       </td>
<td> JSON                    </td>
<td> 54.93                </td>
<td> 16.72                    </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson              </td>
<td> JSON                    </td>
<td> 126.40               </td>
<td> (not supported)          </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf          </td>
<td> Protocol Buffers        </td>
<td> 138.27               </td>
<td> 91.18                    </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf        </td>
<td> Protocol Buffers        </td>
<td> 472.69               </td>
<td> 295.33                   </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto        </td>
<td> Cap&#8217;n Proto             </td>
<td> 2226.71              </td>
<td> 450                      </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto        </td>
<td> Cap&#8217;n Proto (zero copy) </td>
<td> 2226.71              </td>
<td> 1393.3                   </td>
</tr>
<tr>
<td> Rust     </td>
<td> serialize::json     </td>
<td> JSON                    </td>
<td> 89                   </td>
<td> 18                       </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-msgpack        </td>
<td> MessagePack             </td>
<td> 160                  </td>
<td> 52                       </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-protobuf       </td>
<td> Protocol Buffers        </td>
<td> 177                  </td>
<td> 70                       </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust      </td>
<td> Cap&#8217;n Proto (unpacked)  </td>
<td> 1729                 </td>
<td> 1276                     </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust      </td>
<td> Cap&#8217;n Proto (packed)    </td>
<td> 398                  </td>
<td> 246                      </td>
</tr>
</tbody>
</table>


<p>I upgraded to OS X Yosemite, so I think that brought these numbers down overall
from the last post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 2: Performance]]></title>
    <link href="http://erickt.github.io/blog/2014/11/03/performance/"/>
    <updated>2014-11-03T06:38:38-08:00</updated>
    <id>http://erickt.github.io/blog/2014/11/03/performance</id>
    <content type="html"><![CDATA[<p>As I said in the <a href="http://erickt.github.io/blog/2014/10/28/serialization/">last post</a>,
Rust&rsquo;s <code>serialize</code> library, specifically <code>serialize::json</code> is pretty slow.
Back when I started this project a number of months ago, I wanted to benchmark
to see how we compared to some other languages. There are a bunch of JSON
benchmarks, but the one I chose was Cloudflare&rsquo;s Go language.
<a href="https://github.com/cloudflare/goser">Goser</a>, mainly because it was using a
complex real world log structure, and they did the hard work of implementing
benchmarks for <a href="http://golang.org/pkg/encoding/json">encoding/json</a>,
<a href="http://code.google.com/p/goprotobuf/">goprotobuf</a>,
<a href="http://code.google.com/p/gogoprotobuf/">gogoprotobuf</a>, and
<a href="https://github.com/glycerine/go-capnproto">go-capnproto</a>. I also included the
Go <a href="https://github.com/pquerna/ffjson">ffjson</a> and C++
<a href="https://github.com/erickt/rapidjson/blob/master/log.cc">rapidjson</a>, which
both claim to be the fastest JSON libraries for those languages. Here are the
results I got:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library             </th>
<th> format           </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> C++      </td>
<td> rapidjson           </td>
<td> JSON             </td>
<td> 294                  </td>
<td> 164 (DOM) / 192 (SAX)  </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json       </td>
<td> JSON             </td>
<td> 71.47                </td>
<td> 25.09                  </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson              </td>
<td> JSON             </td>
<td> 156.67               </td>
<td> (not supported)        </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf          </td>
<td> Protocol Buffers </td>
<td> 148.78               </td>
<td> 99.57                  </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf        </td>
<td> Protocol Buffers </td>
<td> 519.48               </td>
<td> 319.40                 </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto        </td>
<td> Cap&#8217;n Proto      </td>
<td> 3419.54              </td>
<td> 665.35                 </td>
</tr>
<tr>
<td> Rust     </td>
<td> serialize::json     </td>
<td> JSON             </td>
<td> 40-ish               </td>
<td> 10-ish                 </td>
</tr>
</tbody>
</table>


<p>Notes:</p>

<ul>
<li><code>rapidjson</code> supports both DOM-style and SAX-style deserializing. DOM-style
means deserializing into a generic object, then from there into the final
object, SAX-style means a callback approach where a callback handler is
called for each JSON token.</li>
<li>Go&rsquo;s <code>encoding/json</code> uses reflection to serialize arbitrary values. <code>ffjson</code>
uses code generation to get it&rsquo;s serialization sped, but it doesn&rsquo;t implement
deserialization.</li>
<li>both <code>goprotobuf</code> and <code>gogoprotobuf</code> use code generation, but gogoprotobuf
uses Protocol Buffer&rsquo;s extension support to do cheaper serialization.</li>
<li>Cap&#8217;n Proto doesn&rsquo;t really do serialization, but lays the serialized data out
just like it is in memory so it has nearly zero serialization speed.</li>
<li>The Rust numbers are from a couple months ago and I couldn&rsquo;t track down
the exact numbers.</li>
</ul>


<p>So. Yikes. Not only are we no where near <code>rapidjson</code>, we were being soundly
beaten by Go&rsquo;s reflection-based framework <code>encoding/json</code>.  Even worse, our
compile time was at least 10 times theirs. So, not pretty at all.</p>

<p>But that was a couple months ago. Between then and now, Patrick Walton, Luqman
Aden, myself, and probably lots others found and fixed a number of bugs across
<code>serialize::json</code>, <code>std::io</code>, generic function calls, and more. All this work
got us to more than double our performance:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library           </th>
<th> format               </th>
<th> serialization (MB/s)   </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> serialize::json   </td>
<td> JSON                 </td>
<td> 117                    </td>
<td> 25                     </td>
</tr>
</tbody>
</table>


<p>We&rsquo;re (kind of) beating Go! At least the builtin reflection-based solution.
Better, but not great. I think our challenge is those dang closures. While LLVM
can optimize simple closures, it seems to have a lot of trouble with all these
recursive closure calls. While having finished unboxed closures might finally
let us break through this performance bottleneck, it&rsquo;s not guaranteed.</p>

<p>All in all, this, and the representational problems from
<a href="http://erickt.github.io/blog/2014/10/28/serialization/">post 1</a> make it pretty
obvious we got some fundamental issues here and we need to use an alternative
solution. Next post I&rsquo;ll start getting into the details of the design of
<a href="https://github.com/erickt/rust-serde">serde</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 1]]></title>
    <link href="http://erickt.github.io/blog/2014/10/28/serialization/"/>
    <updated>2014-10-28T08:52:18-07:00</updated>
    <id>http://erickt.github.io/blog/2014/10/28/serialization</id>
    <content type="html"><![CDATA[<p>Hello everybody! It&rsquo;s been, what, <em>two</em> years since I last blogged? Not my best
performance, I&rsquo;m sorry to say. So for all of my 3 pageviews that are probably
bots, I appologize for such a long delay on updating my blog. I got to say I&rsquo;ve
been pretty inspired by the great <a href="http://jvns.ca/">Julia Evans</a> (who I hope we
can someday get back to working on rust stuff). She&rsquo;s an epic blogger, and I
hope I can get somewhere near that speed.</p>

<p>Anyway, on to the post. My main on-again-off-again project this past year has
been working Rust&rsquo;s generic <a href="http://doc.rust-lang.org/serialize/">serialize</a>
library. If you haven&rsquo;t played with it yet, it&rsquo;s really nifty. It&rsquo;s a generic
framework that allows a generic <code>Encoder</code> serialize a generic <code>Encodable</code>, and
the inverse with <code>Decoder</code> and <code>Decodable</code>. This allows you to write just one
<code>Encodable</code> impl that can transparently work with our
<a href="http://doc.rust-lang.org/serialize/">json</a> library,
<a href="https://github.com/mneumann/rust-msgpack">msgpack</a>,
<a href="https://github.com/alexcrichton/toml-rs">toml</a>, and etc. It&rsquo;s simple to use
too in most cases as you can use <code>#[deriving(Encodable, Decodable)]</code> to
automatically create a implementation for your type. Here&rsquo;s an example:</p>

<pre><code class="rust">extern crate serialize;

use serialize::json;

#[deriving(Encodable, Decodable, Show)]
struct Employee {
    name: String,
}

#[deriving(Encodable, Decodable, Show)]
struct Company {
    employees: Vec&lt;Employee&gt;,
}

fn main() {
    let company = Company {
        employees: vec![
            Employee { name: "Dan".to_string() },
            Employee { name: "Erin".to_string() },
            Employee { name: "Jeff".to_string() },
            Employee { name: "Spencer".to_string() },
        ],
    };

    let s = json::encode(&amp;company);
    let company: Company = json::decode(s.as_slice()).unwrap();
}
</code></pre>

<p>There are some downsides to serialize though. Manually implementing can be a
bit of a pain. Here&rsquo;s the example from before:</p>

<pre><code class="rust">impl&lt;S: Encoder&lt;E&gt;, E&gt; Encodable&lt;S, E&gt; for Employee {
    fn encode(&amp;self, s: &amp;mut S) -&gt; Result&lt;(), E&gt; {
        match *self {
            Employee { name: ref name } =&gt; {
                s.emit_struct("Employee", 1u, |s| {
                    s.emit_struct_field("name", 0u, |s| name.encode(s))
                })
            }
        }
    }
}

impl&lt;D: Decoder&lt;E&gt;, E&gt; Decodable&lt;D, E&gt; for Employee {
    fn decode(d: &amp;mut D) -&gt; Result&lt;Employee, E&gt; {
        d.read_struct("Employee", 1u, |d| {
            Ok(Employee {
                name: {
                    try!(d.read_struct_field("name", 0u, |d| {
                        Decodable::decode(d)
                    }))
                }
            })
        })
    }
}
</code></pre>

<p>As you can see, parsing compound structures requires these recursive closure
calls in order to perform the handshake between the <code>Encoder</code> and the
<code>Encodable</code>. A couple people have run into bugs in the past where they didn&rsquo;t
implement this pattern, which results in some confusing bugs. Furthermore, LLVM
isn&rsquo;t great at inlining these recursive calls, so <code>serialize</code> impls tend to not
perform well.</p>

<p>That&rsquo;s not the worst of it though. The real problem is that there are types
that can implement <code>Encodable</code>, there&rsquo;s no way to write a <code>Decodable</code>
implementation. They&rsquo;re pretty common too. For example, the
<code>serialize::json::Json</code> type:</p>

<pre><code class="rust">pub enum Json {
    I64(i64),
    U64(u64),
    F64(f64),
    String(string::String),
    Boolean(bool),
    List(JsonList),
    Object(JsonObject),
    Null,
}

pub type JsonList = Vec&lt;Json&gt;;
pub type JsonObject = TreeMap&lt;string::String, Json&gt;;
</code></pre>

<p>The <code>Json</code> value can represent any value that&rsquo;s in a JSON string. Implied in
this is the notion that the <code>Decodable</code> has to look ahead to see what the next
value is so it can decide which <code>Json</code> variant to construct. Unfortunately our
current <code>Decoder</code> infrastructure doesn&rsquo;t support lookahead. The way the
<code>Decoder</code>/<code>Decodable</code> handshake works is essentially:</p>

<ul>
<li><code>Decodable</code> asks for a struct named <code>"Employee"</code>.</li>
<li><code>Decodable</code> asks for a field named <code>"name"</code>.</li>
<li><code>Decodable</code> asks for a value of type <code>String</code>.</li>
<li><code>Decodable</code> asks for a field named <code>"age"</code>.</li>
<li><code>Decodable</code> asks for a value of type <code>uint</code>.</li>
<li>&hellip;</li>
</ul>


<p>Any deviation from this pattern results in an error. There isn&rsquo;t a way for the
<code>Decodable</code> to ask what is the type of the next value, so this is why we
serialize generic enums by explicitly tagging the variant, as in:</p>

<pre><code>extern crate serialize;

use serialize::json;

#[deriving(Encodable, Decodable, Show)]
enum Animal {
    Dog(uint),
    Frog(String, uint),
}

fn main() {
    let animal = Frog("Frank".to_string(), 349);

    let s = json::encode(&amp;animal);

    println!("{}", s);
    // prints {"variant":"Frog","fields":["Frank",349]}
}
</code></pre>

<p>That&rsquo;s probably good enough for now. In my next post I&rsquo;ll go into in my
approach to fix this in <a href="https://github.com/erickt/rust-serde">serde</a>.</p>
]]></content>
  </entry>
  
</feed>
