<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Serialization | Tilting at Rabbit Holes]]></title>
  <link href="http://erickt.github.io/blog/categories/serialization/atom.xml" rel="self"/>
  <link href="http://erickt.github.io/"/>
  <updated>2014-11-23T21:33:54-08:00</updated>
  <id>http://erickt.github.io/</id>
  <author>
    <name><![CDATA[Erick Tryzelaar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 2.2: More Benchmarks]]></title>
    <link href="http://erickt.github.io/blog/2014/11/13/benchmarks-2/"/>
    <updated>2014-11-13T09:07:36-08:00</updated>
    <id>http://erickt.github.io/blog/2014/11/13/benchmarks-2</id>
    <content type="html"><![CDATA[<p>Back to the benchmarks! I got some great comments on
<a href="https://www.reddit.com/r/rust/comments/2lzc9n/rust_serialization_part_21_now_with_more/">reddit</a>,
So I wanted to do another post to update my numbers. Here&rsquo;s what I changed:</p>

<ul>
<li>I wasn&rsquo;t consistent on whether or not the serialization benchmarks included
Some tests are including the allocation of a buffer to write into. I&rsquo;ve
  changed it so most are reusing one, which speeds everything up (especially
capnproto-rust!). This does depend on
<a href="https://github.com/rust-lang/rust/pull/18885">#18885</a> landing though.</li>
<li>I&rsquo;ve added <a href="https://github.com/TyOverby/bincode">bincode</a>, which serializes
values as raw bytes. Quite speedy too! Not nearly as fast as Cap&#8217;n Proto though.</li>
<li>I&rsquo;ve changed <code>C++</code> and <code>Rust</code> JSON tests to serialize enums as uints.</li>
<li>I added the time it takes to create the populate the structures. I&rsquo;m betting
  the reason the Rust numbers are so high is that we&rsquo;re allocating strings. Not
sure if the other languages are able to avoid that allocation.</li>
</ul>


<hr />

<p>JSON:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library         </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> serialize::json </td>
<td> 1127            </td>
<td> 117                  </td>
<td> 26                     </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson (dom) </td>
<td> 546             </td>
<td> 281                  </td>
<td> 144                    </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson (dom) </td>
<td> 546             </td>
<td> 281                  </td>
<td> 181                    </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json   </td>
<td> 343             </td>
<td> 63.99                </td>
<td> 22.46                  </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson          </td>
<td> 343             </td>
<td> 144.60               </td>
<td> (not supported)        </td>
</tr>
</tbody>
</table>


<hr />

<p>Cap&#8217;n Proto:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library                   </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> capnproto-rust (unpacked) </td>
<td> 325             </td>
<td> 4977                 </td>
<td> 2251                   </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust (packed)   </td>
<td> 325             </td>
<td> 398                  </td>
<td> 246                    </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto              </td>
<td> 2368            </td>
<td> 2226.71              </td>
<td> 450                    </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto (zero copy)  </td>
<td> 2368            </td>
<td> 2226.71              </td>
<td> 1393.3                 </td>
</tr>
</tbody>
</table>


<hr />

<p>Protocol Buffers:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library       </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> rust-protobuf </td>
<td> 1041            </td>
<td> 370                  </td>
<td> 118                    </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf    </td>
<td> 1133            </td>
<td> 138.27               </td>
<td> 91.18                  </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf  </td>
<td> 343             </td>
<td> 472.69               </td>
<td> 295.33                 </td>
</tr>
</tbody>
</table>


<hr />

<p>Misc:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library      </th>
<th> population (ns) </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> rust-msgpack </td>
<td> 1143            </td>
<td> 454                  </td>
<td> 144                    </td>
</tr>
<tr>
<td> Rust     </td>
<td> bincode      </td>
<td> 1143            </td>
<td> 1149                 </td>
<td> 82                     </td>
</tr>
</tbody>
</table>


<p>Anyone want to add more C/Go/Rust/Java/etc benchmarks?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 2.1: Benchmarks]]></title>
    <link href="http://erickt.github.io/blog/2014/11/11/benchmarks/"/>
    <updated>2014-11-11T08:11:34-08:00</updated>
    <id>http://erickt.github.io/blog/2014/11/11/benchmarks</id>
    <content type="html"><![CDATA[<p>After <a href="http://erickt.github.io/blog/2014/11/03/performance/">part 2</a> I received
a couple requests to add in a couple other rust serialization libraries. So one
thing led to another, and now I&rsquo;ve got a benchmark suite I&rsquo;m calling
<a href="https://github.com/erickt/rust-serialization-benchmarks">rust-serialization-benchmarks</a>.
Really creative name, eh? This includes all the other benchmarks I referred to
previously, as well as <a href="https://github.com/dwrensha/capnproto-rust">capnproto</a>,
<a href="https://github.com/mneumann/rust-msgpack">msgpack</a>, and
<a href="https://github.com/stepancheg/rust-protobuf">protobuf</a>.</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library             </th>
<th> format                  </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s)   </th>
</tr>
</thead>
<tbody>
<tr>
<td> C++      </td>
<td> rapidjson           </td>
<td> JSON (dom)              </td>
<td> 233                  </td>
<td> 102                      </td>
</tr>
<tr>
<td> C++      </td>
<td> rapidjson           </td>
<td> JSON (sax)              </td>
<td> 233                  </td>
<td> 124                      </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json       </td>
<td> JSON                    </td>
<td> 54.93                </td>
<td> 16.72                    </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson              </td>
<td> JSON                    </td>
<td> 126.40               </td>
<td> (not supported)          </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf          </td>
<td> Protocol Buffers        </td>
<td> 138.27               </td>
<td> 91.18                    </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf        </td>
<td> Protocol Buffers        </td>
<td> 472.69               </td>
<td> 295.33                   </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto        </td>
<td> Cap&#8217;n Proto             </td>
<td> 2226.71              </td>
<td> 450                      </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto        </td>
<td> Cap&#8217;n Proto (zero copy) </td>
<td> 2226.71              </td>
<td> 1393.3                   </td>
</tr>
<tr>
<td> Rust     </td>
<td> serialize::json     </td>
<td> JSON                    </td>
<td> 89                   </td>
<td> 18                       </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-msgpack        </td>
<td> MessagePack             </td>
<td> 160                  </td>
<td> 52                       </td>
</tr>
<tr>
<td> Rust     </td>
<td> rust-protobuf       </td>
<td> Protocol Buffers        </td>
<td> 177                  </td>
<td> 70                       </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust      </td>
<td> Cap&#8217;n Proto (unpacked)  </td>
<td> 1729                 </td>
<td> 1276                     </td>
</tr>
<tr>
<td> Rust     </td>
<td> capnproto-rust      </td>
<td> Cap&#8217;n Proto (packed)    </td>
<td> 398                  </td>
<td> 246                      </td>
</tr>
</tbody>
</table>


<p>I upgraded to OS X Yosemite, so I think that brought these numbers down overall
from the last post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 2: Performance]]></title>
    <link href="http://erickt.github.io/blog/2014/11/03/performance/"/>
    <updated>2014-11-03T06:38:38-08:00</updated>
    <id>http://erickt.github.io/blog/2014/11/03/performance</id>
    <content type="html"><![CDATA[<p>As I said in the <a href="http://erickt.github.io/blog/2014/10/28/serialization/">last post</a>,
Rust&rsquo;s <code>serialize</code> library, specifically <code>serialize::json</code> is pretty slow.
Back when I started this project a number of months ago, I wanted to benchmark
to see how we compared to some other languages. There are a bunch of JSON
benchmarks, but the one I chose was Cloudflare&rsquo;s Go language.
<a href="https://github.com/cloudflare/goser">Goser</a>, mainly because it was using a
complex real world log structure, and they did the hard work of implementing
benchmarks for <a href="http://golang.org/pkg/encoding/json">encoding/json</a>,
<a href="http://code.google.com/p/goprotobuf/">goprotobuf</a>,
<a href="http://code.google.com/p/gogoprotobuf/">gogoprotobuf</a>, and
<a href="https://github.com/glycerine/go-capnproto">go-capnproto</a>. I also included the
Go <a href="https://github.com/pquerna/ffjson">ffjson</a> and C++
<a href="https://github.com/erickt/rapidjson/blob/master/log.cc">rapidjson</a>, which
both claim to be the fastest JSON libraries for those languages. Here are the
results I got:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library             </th>
<th> format           </th>
<th> serialization (MB/s) </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> C++      </td>
<td> rapidjson           </td>
<td> JSON             </td>
<td> 294                  </td>
<td> 164 (DOM) / 192 (SAX)  </td>
</tr>
<tr>
<td> Go       </td>
<td> encoding/json       </td>
<td> JSON             </td>
<td> 71.47                </td>
<td> 25.09                  </td>
</tr>
<tr>
<td> Go       </td>
<td> ffjson              </td>
<td> JSON             </td>
<td> 156.67               </td>
<td> (not supported)        </td>
</tr>
<tr>
<td> Go       </td>
<td> goprotobuf          </td>
<td> Protocol Buffers </td>
<td> 148.78               </td>
<td> 99.57                  </td>
</tr>
<tr>
<td> Go       </td>
<td> gogoprotobuf        </td>
<td> Protocol Buffers </td>
<td> 519.48               </td>
<td> 319.40                 </td>
</tr>
<tr>
<td> Go       </td>
<td> go-capnproto        </td>
<td> Cap&#8217;n Proto      </td>
<td> 3419.54              </td>
<td> 665.35                 </td>
</tr>
<tr>
<td> Rust     </td>
<td> serialize::json     </td>
<td> JSON             </td>
<td> 40-ish               </td>
<td> 10-ish                 </td>
</tr>
</tbody>
</table>


<p>Notes:</p>

<ul>
<li><code>rapidjson</code> supports both DOM-style and SAX-style deserializing. DOM-style
means deserializing into a generic object, then from there into the final
object, SAX-style means a callback approach where a callback handler is
called for each JSON token.</li>
<li>Go&rsquo;s <code>encoding/json</code> uses reflection to serialize arbitrary values. <code>ffjson</code>
uses code generation to get it&rsquo;s serialization sped, but it doesn&rsquo;t implement
deserialization.</li>
<li>both <code>goprotobuf</code> and <code>gogoprotobuf</code> use code generation, but gogoprotobuf
uses Protocol Buffer&rsquo;s extension support to do cheaper serialization.</li>
<li>Cap&#8217;n Proto doesn&rsquo;t really do serialization, but lays the serialized data out
just like it is in memory so it has nearly zero serialization speed.</li>
<li>The Rust numbers are from a couple months ago and I couldn&rsquo;t track down
the exact numbers.</li>
</ul>


<p>So. Yikes. Not only are we no where near <code>rapidjson</code>, we were being soundly
beaten by Go&rsquo;s reflection-based framework <code>encoding/json</code>.  Even worse, our
compile time was at least 10 times theirs. So, not pretty at all.</p>

<p>But that was a couple months ago. Between then and now, Patrick Walton, Luqman
Aden, myself, and probably lots others found and fixed a number of bugs across
<code>serialize::json</code>, <code>std::io</code>, generic function calls, and more. All this work
got us to more than double our performance:</p>

<table>
<thead>
<tr>
<th> language </th>
<th> library           </th>
<th> format               </th>
<th> serialization (MB/s)   </th>
<th> deserialization (MB/s) </th>
</tr>
</thead>
<tbody>
<tr>
<td> Rust     </td>
<td> serialize::json   </td>
<td> JSON                 </td>
<td> 117                    </td>
<td> 25                     </td>
</tr>
</tbody>
</table>


<p>We&rsquo;re (kind of) beating Go! At least the builtin reflection-based solution.
Better, but not great. I think our challenge is those dang closures. While LLVM
can optimize simple closures, it seems to have a lot of trouble with all these
recursive closure calls. While having finished unboxed closures might finally
let us break through this performance bottleneck, it&rsquo;s not guaranteed.</p>

<p>All in all, this, and the representational problems from
<a href="http://erickt.github.io/blog/2014/10/28/serialization/">post 1</a> make it pretty
obvious we got some fundamental issues here and we need to use an alternative
solution. Next post I&rsquo;ll start getting into the details of the design of
<a href="https://github.com/erickt/rust-serde">serde</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewriting Rust Serialization, Part 1]]></title>
    <link href="http://erickt.github.io/blog/2014/10/28/serialization/"/>
    <updated>2014-10-28T08:52:18-07:00</updated>
    <id>http://erickt.github.io/blog/2014/10/28/serialization</id>
    <content type="html"><![CDATA[<p>Hello everybody! It&rsquo;s been, what, <em>two</em> years since I last blogged? Not my best
performance, I&rsquo;m sorry to say. So for all of my 3 pageviews that are probably
bots, I appologize for such a long delay on updating my blog. I got to say I&rsquo;ve
been pretty inspired by the great <a href="http://jvns.ca/">Julia Evans</a> (who I hope we
can someday get back to working on rust stuff). She&rsquo;s an epic blogger, and I
hope I can get somewhere near that speed.</p>

<p>Anyway, on to the post. My main on-again-off-again project this past year has
been working Rust&rsquo;s generic <a href="http://doc.rust-lang.org/serialize/">serialize</a>
library. If you haven&rsquo;t played with it yet, it&rsquo;s really nifty. It&rsquo;s a generic
framework that allows a generic <code>Encoder</code> serialize a generic <code>Encodable</code>, and
the inverse with <code>Decoder</code> and <code>Decodable</code>. This allows you to write just one
<code>Encodable</code> impl that can transparently work with our
<a href="http://doc.rust-lang.org/serialize/">json</a> library,
<a href="https://github.com/mneumann/rust-msgpack">msgpack</a>,
<a href="https://github.com/alexcrichton/toml-rs">toml</a>, and etc. It&rsquo;s simple to use
too in most cases as you can use <code>#[deriving(Encodable, Decodable)]</code> to
automatically create a implementation for your type. Here&rsquo;s an example:</p>

<pre><code class="rust">extern crate serialize;

use serialize::json;

#[deriving(Encodable, Decodable, Show)]
struct Employee {
    name: String,
}

#[deriving(Encodable, Decodable, Show)]
struct Company {
    employees: Vec&lt;Employee&gt;,
}

fn main() {
    let company = Company {
        employees: vec![
            Employee { name: "Dan".to_string() },
            Employee { name: "Erin".to_string() },
            Employee { name: "Jeff".to_string() },
            Employee { name: "Spencer".to_string() },
        ],
    };

    let s = json::encode(&amp;company);
    let company: Company = json::decode(s.as_slice()).unwrap();
}
</code></pre>

<p>There are some downsides to serialize though. Manually implementing can be a
bit of a pain. Here&rsquo;s the example from before:</p>

<pre><code class="rust">impl&lt;S: Encoder&lt;E&gt;, E&gt; Encodable&lt;S, E&gt; for Employee {
    fn encode(&amp;self, s: &amp;mut S) -&gt; Result&lt;(), E&gt; {
        match *self {
            Employee { name: ref name } =&gt; {
                s.emit_struct("Employee", 1u, |s| {
                    s.emit_struct_field("name", 0u, |s| name.encode(s))
                })
            }
        }
    }
}

impl&lt;D: Decoder&lt;E&gt;, E&gt; Decodable&lt;D, E&gt; for Employee {
    fn decode(d: &amp;mut D) -&gt; Result&lt;Employee, E&gt; {
        d.read_struct("Employee", 1u, |d| {
            Ok(Employee {
                name: {
                    try!(d.read_struct_field("name", 0u, |d| {
                        Decodable::decode(d)
                    }))
                }
            })
        })
    }
}
</code></pre>

<p>As you can see, parsing compound structures requires these recursive closure
calls in order to perform the handshake between the <code>Encoder</code> and the
<code>Encodable</code>. A couple people have run into bugs in the past where they didn&rsquo;t
implement this pattern, which results in some confusing bugs. Furthermore, LLVM
isn&rsquo;t great at inlining these recursive calls, so <code>serialize</code> impls tend to not
perform well.</p>

<p>That&rsquo;s not the worst of it though. The real problem is that there are types
that can implement <code>Encodable</code>, there&rsquo;s no way to write a <code>Decodable</code>
implementation. They&rsquo;re pretty common too. For example, the
<code>serialize::json::Json</code> type:</p>

<pre><code class="rust">pub enum Json {
    I64(i64),
    U64(u64),
    F64(f64),
    String(string::String),
    Boolean(bool),
    List(JsonList),
    Object(JsonObject),
    Null,
}

pub type JsonList = Vec&lt;Json&gt;;
pub type JsonObject = TreeMap&lt;string::String, Json&gt;;
</code></pre>

<p>The <code>Json</code> value can represent any value that&rsquo;s in a JSON string. Implied in
this is the notion that the <code>Decodable</code> has to look ahead to see what the next
value is so it can decide which <code>Json</code> variant to construct. Unfortunately our
current <code>Decoder</code> infrastructure doesn&rsquo;t support lookahead. The way the
<code>Decoder</code>/<code>Decodable</code> handshake works is essentially:</p>

<ul>
<li><code>Decodable</code> asks for a struct named <code>"Employee"</code>.</li>
<li><code>Decodable</code> asks for a field named <code>"name"</code>.</li>
<li><code>Decodable</code> asks for a value of type <code>String</code>.</li>
<li><code>Decodable</code> asks for a field named <code>"age"</code>.</li>
<li><code>Decodable</code> asks for a value of type <code>uint</code>.</li>
<li>&hellip;</li>
</ul>


<p>Any deviation from this pattern results in an error. There isn&rsquo;t a way for the
<code>Decodable</code> to ask what is the type of the next value, so this is why we
serialize generic enums by explicitly tagging the variant, as in:</p>

<pre><code>extern crate serialize;

use serialize::json;

#[deriving(Encodable, Decodable, Show)]
enum Animal {
    Dog(uint),
    Frog(String, uint),
}

fn main() {
    let animal = Frog("Frank".to_string(), 349);

    let s = json::encode(&amp;animal);

    println!("{}", s);
    // prints {"variant":"Frog","fields":["Frank",349]}
}
</code></pre>

<p>That&rsquo;s probably good enough for now. In my next post I&rsquo;ll go into in my
approach to fix this in <a href="https://github.com/erickt/rust-serde">serde</a>.</p>
]]></content>
  </entry>
  
</feed>
